{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import GlobalAveragePooling2D, TimeDistributed, Dense, LSTM, GRU, Conv2D, MaxPooling2D, Flatten \n",
    "from keras.layers import Input, Rescaling, BatchNormalization, Activation, SeparableConv2D, Reshape, SimpleRNN \n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.applications.densenet import DenseNet169\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import os\n",
    "from pathlib import Path\n",
    "from imutils import paths\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_soft_device_placement(True)\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape =  (224, 224, 3)\n",
    "batch_size = 64\n",
    "time_dist = 8\n",
    "trsplit = (0.0, 0.7)\n",
    "valsplit = (0.7, 0.85)\n",
    "tesplit = (0.85, 1.0)\n",
    "\n",
    "org_path = Path(r\"C:\\Users\\SWQA\\Desktop\\STAJ\\Metamorphose\\Videos\\1\")\n",
    "class_paths = [Path(r\"class08_30_20\"), Path(r\"classsenay_1\"), Path(r\"class16_46_57\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "7750\n",
      "216\n",
      "1769\n",
      "9735\n"
     ]
    }
   ],
   "source": [
    "all_labels = [i for i in os.walk(org_path / class_paths[0] / \"Train\" / \"Label\")][0][2]\n",
    "\n",
    "lie_len = len([i for i in all_labels if i.endswith(\"l.jpeg\")])\n",
    "err_len = len([i for i in all_labels if i.endswith(\"e.jpeg\")])\n",
    "both_len = len(all_labels) - lie_len - err_len\n",
    "none_len = len(list(os.walk(org_path / class_paths[0] / \"Train\"))[0][2]) - len(all_labels)\n",
    "all_len = lie_len + err_len + both_len + none_len\n",
    "print(both_len)\n",
    "print(lie_len)\n",
    "print(err_len)\n",
    "print(none_len)\n",
    "print(all_len)\n",
    "\n",
    "class_count = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9735000000.0\n",
      "0.31403225805438606\n",
      "11.267361098070184\n",
      "1.3757772751023492\n"
     ]
    }
   ],
   "source": [
    "lie_weight = all_len / ((class_count * lie_len) + 0.000001)\n",
    "err_weight = all_len / ((class_count * err_len) + 0.000001)\n",
    "both_weight = all_len / ((class_count * both_len) + 0.000001)\n",
    "none_weight = all_len / ((class_count * none_len) + 0.000001)\n",
    "print(both_weight)\n",
    "print(lie_weight)\n",
    "print(err_weight)\n",
    "print(none_weight)\n",
    "\n",
    "weight_dict = [\n",
    "    lie_weight,\n",
    "    err_weight,\n",
    "    both_weight,\n",
    "    none_weight\n",
    "]\n",
    "weight_dict2 = {\n",
    "    both_weight: [1, 0],\n",
    "    lie_weight:  [0, 1],\n",
    "    err_weight:  [1, 1],\n",
    "    none_weight: [0, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ins_ind(string, char, index):\n",
    "        return string[:index] + char + string[index:] \n",
    "\n",
    "def __data_gen(wtype, iclass, split):    \n",
    "    imgs = []    \n",
    "    lbls = []\n",
    "    weights = []\n",
    "    img_dist = []\n",
    "    lbls = []\n",
    "    weight_dist = []\n",
    "    \n",
    "    bcounter = 0\n",
    "    \n",
    "    seed = 0\n",
    "    for c in wtype:\n",
    "        seed += ord(c)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    shuffled = np.asarray(sorted(list(os.walk(org_path / class_paths[0] / \"Train\"))[0][2], key=lambda x: len(x)))\n",
    "    shuffled = shuffled[int(len(shuffled) * split[0]):int(len(shuffled) * split[1])]\n",
    "    # np.random.shuffle(shuffled)\n",
    "\n",
    "    #unroll\n",
    "    for p in shuffled[:time_dist]:        \n",
    "        img = cv2.imread(str(org_path / iclass / wtype / p), cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, input_shape[:-1])\n",
    "        \n",
    "        img_dist.append(img)\n",
    "\n",
    "        if os.path.isfile(org_path / iclass / wtype / \"Label\" / shuffled[time_dist]):\n",
    "            weight_dist.append(both_weight)\n",
    "        elif os.path.isfile(org_path / iclass / wtype / \"Label\" / ins_ind(shuffled[time_dist], 'l', shuffled[time_dist].index('.'))):\n",
    "            weight_dist.append(lie_weight)\n",
    "        elif os.path.isfile(org_path / iclass / wtype / \"Label\" / ins_ind(shuffled[time_dist], 'e', shuffled[time_dist].index('.'))):\n",
    "            weight_dist.append(err_weight)\n",
    "        else:\n",
    "            weight_dist.append(none_weight)\n",
    "\n",
    "    if os.path.isfile(org_path / iclass / wtype / \"Label\" / shuffled[time_dist]):\n",
    "        lbls.append([1, 1])\n",
    "    elif os.path.isfile(org_path / iclass / wtype / \"Label\" / ins_ind(shuffled[time_dist], 'l', shuffled[time_dist].index('.'))):\n",
    "        lbls.append([1, 0])\n",
    "    elif os.path.isfile(org_path / iclass / wtype / \"Label\" / ins_ind(shuffled[time_dist], 'e', shuffled[time_dist].index('.'))):\n",
    "        lbls.append([0, 1])\n",
    "    else:\n",
    "        lbls.append([0, 0])\n",
    "\n",
    "\n",
    "    imgs.append(np.asarray(img_dist, dtype=np.uint8))\n",
    "    weights.append(np.asarray(weight_dist, dtype=np.float32))\n",
    "\n",
    "    bcounter += 1\n",
    "\n",
    "    for p in range(time_dist, len(shuffled) - 1):\n",
    "        img_index = shuffled[p]\n",
    "        lbl_index = shuffled[p + 1]\n",
    "\n",
    "        img = cv2.imread(str(org_path / iclass / wtype / img_index), cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, input_shape[:-1])\n",
    "\n",
    "        img_dist.append(img)\n",
    "        del img_dist[0]\n",
    "\n",
    "        if os.path.isfile(org_path / iclass / wtype / \"Label\" / lbl_index):\n",
    "            lbls.append([1, 1])\n",
    "            weight_dist.append(both_weight)\n",
    "        elif os.path.isfile(org_path / iclass / wtype / \"Label\" / ins_ind(lbl_index, 'l', lbl_index.index('.'))):\n",
    "            lbls.append([1, 0])\n",
    "            weight_dist.append(lie_weight)\n",
    "        elif os.path.isfile(org_path / iclass / wtype / \"Label\" / ins_ind(lbl_index, 'e', lbl_index.index('.'))):\n",
    "            lbls.append([0, 1])\n",
    "            weight_dist.append(err_weight)\n",
    "        else:\n",
    "            lbls.append([0, 0])\n",
    "            weight_dist.append(none_weight)\n",
    "        del weight_dist[0]\n",
    "\n",
    "        imgs.append(np.asarray(img_dist, dtype=np.uint8))\n",
    "        weights.append(np.asarray(weight_dist, dtype=np.float32))\n",
    "\n",
    "        bcounter += 1\n",
    "\n",
    "        if bcounter % batch_size == 0:\n",
    "            bcounter = 0\n",
    "            yield (np.asarray(imgs, dtype=np.uint8), np.asarray(lbls, dtype=np.float32))\n",
    "            imgs = []\n",
    "            lbls = []\n",
    "            weights = []\n",
    "\n",
    "def load_data():\n",
    "    signature = (\n",
    "        tf.TensorSpec(shape=(batch_size, time_dist, *input_shape), dtype=tf.uint8),\n",
    "        tf.TensorSpec(shape=(batch_size, *(2,)), dtype=tf.float32),\n",
    "        # tf.TensorSpec(shape=(batch_size, time_dist), dtype=tf.float32)\n",
    "    )\n",
    "    \n",
    "    for iclass in class_paths:\n",
    "        trdir_path = org_path / iclass / \"Train\"\n",
    "        valdir_path = org_path / iclass / \"Val\"\n",
    "        tedir_path = org_path / iclass / \"Test\"\n",
    "        \n",
    "        train_dataset = tf.data.Dataset.from_generator(\n",
    "            lambda: __data_gen(\"Train\", iclass, trsplit),\n",
    "            output_signature=signature\n",
    "        )\n",
    "\n",
    "        val_dataset = tf.data.Dataset.from_generator(\n",
    "            lambda: __data_gen(\"Train\", iclass, valsplit),\n",
    "            output_signature=signature\n",
    "        )\n",
    "\n",
    "        test_dataset = tf.data.Dataset.from_generator(\n",
    "            lambda: __data_gen(\"Train\", iclass, tesplit),\n",
    "            output_signature=signature\n",
    "        )\n",
    "        \n",
    "        return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, val, te = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tr.shuffle(256)\n",
    "val = val.shuffle(256)\n",
    "te = te.shuffle(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tr:\n",
    "    print(t[1])\n",
    "    plt.imshow(t[0][0][0], interpolation='nearest')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "sota_cnn = MobileNetV2(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(time_dist, *input_shape), batch_size=batch_size, dtype=tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metamorph_loss(weights):\n",
    "    def inner_loss(y_true, y_pred):\n",
    "        warr = tf.not_equal(y_true, 1)\n",
    "        warr = warr\n",
    "\n",
    "        cw = []\n",
    "        for w in warr:\n",
    "            temp = np.empty((1,), dtype=np.float32)\n",
    "            if tf.reduce_all(tf.math.logical_xor(w, tf.constant([True, False]))):\n",
    "                temp.fill(weights[0])\n",
    "            elif tf.reduce_all(tf.math.logical_xor(w, tf.constant([False, True]))):\n",
    "                temp.fill(weights[1])\n",
    "            elif tf.reduce_all(tf.math.logical_xor(w, tf.constant([True, True]))):\n",
    "                temp.fill(weights[2])\n",
    "            elif tf.reduce_all(tf.math.logical_xor(w, tf.constant([False, False]))):\n",
    "                temp.fill(weights[3])\n",
    "\n",
    "            cw.append(temp)\n",
    "        \n",
    "        loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.0001)(y_true, y_pred, sample_weight=np.asarray(cw))\n",
    "        \n",
    "        # tf.print(\"TRUEEEEEE\")\n",
    "        # tf.print(type(y_true))\n",
    "        # tf.print(y_true)\n",
    "        # tf.print(\"PREDDDDDD\")\n",
    "        # tf.print(type(y_pred))\n",
    "        # tf.print(y_pred)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    return inner_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "xx = TimeDistributed(sota_cnn)(inputs)\n",
    "xx = TimeDistributed(Flatten())(xx)\n",
    "xx = LSTM(\n",
    "    8,\n",
    "    activation=\"relu\",\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    unroll=True,\n",
    "    stateful=True)(xx)\n",
    "xx = LSTM(\n",
    "    8,\n",
    "    activation=\"relu\",\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    unroll=True,\n",
    "    stateful=True)(xx)\n",
    "xx = LSTM(\n",
    "    8,\n",
    "    activation=\"relu\",\n",
    "    unroll=True,\n",
    "    stateful=True)(xx)\n",
    "out = Dense(2, activation='softmax')(xx)\n",
    "\n",
    "metamorph = tf.keras.Model(inputs, out)\n",
    "\n",
    "for layer in sota_cnn.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "metamorph.compile(    \n",
    "    optimizer='Adam',\n",
    "    loss=metamorph_loss(weight_dict),\n",
    "    metrics=[        \n",
    "        tf.keras.metrics.MeanSquaredError(),\n",
    "        tf.keras.metrics.RootMeanSquaredError(),\n",
    "        tf.keras.metrics.FalseNegatives(),\n",
    "        tf.keras.metrics.TrueNegatives(),\n",
    "        tf.keras.metrics.FalsePositives(),\n",
    "        tf.keras.metrics.TruePositives(),\n",
    "        \"binary_accuracy\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(64, 8, 224, 224,   0           []                               \n",
      "                                3)]                                                               \n",
      "                                                                                                  \n",
      " time_distributed_36 (TimeDistr  (64, 8, 7, 7, 1280)  2257984    ['input_16[0][0]']               \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " time_distributed_37 (TimeDistr  (64, 8, 62720)      0           ['time_distributed_36[0][0]']    \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " lstm_54 (LSTM)                 [(64, 8, 8),         2007328     ['time_distributed_37[0][0]']    \n",
      "                                 (64, 8),                                                         \n",
      "                                 (64, 8)]                                                         \n",
      "                                                                                                  \n",
      " lstm_55 (LSTM)                 [(64, 8, 8),         544         ['lstm_54[0][0]',                \n",
      "                                 (64, 8),                         'lstm_54[0][1]',                \n",
      "                                 (64, 8)]                         'lstm_54[0][2]']                \n",
      "                                                                                                  \n",
      " lstm_56 (LSTM)                 (64, 8)              544         ['lstm_55[0][0]',                \n",
      "                                                                  'lstm_55[0][1]',                \n",
      "                                                                  'lstm_55[0][2]']                \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (64, 2)              18          ['lstm_56[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,266,418\n",
      "Trainable params: 2,008,434\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "metamorph.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "106/106 [==============================] - 77s 702ms/step - loss: 2846.4741 - mean_squared_error: 0.5649 - root_mean_squared_error: 0.7516 - false_negatives_19: 3673.0000 - true_negatives_19: 3111.0000 - false_positives_19: 4846.0000 - true_positives_19: 1938.0000 - binary_accuracy: 0.3721 - val_loss: 3157.6477 - val_mean_squared_error: 0.5644 - val_root_mean_squared_error: 0.7513 - val_false_negatives_19: 795.0000 - val_true_negatives_19: 613.0000 - val_false_positives_19: 795.0000 - val_true_positives_19: 613.0000 - val_binary_accuracy: 0.4354\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 73s 692ms/step - loss: 2679.7881 - mean_squared_error: 0.5173 - root_mean_squared_error: 0.7192 - false_negatives_19: 2808.0000 - true_negatives_19: 3976.0000 - false_positives_19: 3981.0000 - true_positives_19: 2803.0000 - binary_accuracy: 0.4996 - val_loss: nan - val_mean_squared_error: nan - val_root_mean_squared_error: nan - val_false_negatives_19: 686.0000 - val_true_negatives_19: 730.0000 - val_false_positives_19: 678.0000 - val_true_positives_19: 722.0000 - val_binary_accuracy: 0.5156\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 79s 742ms/step - loss: nan - mean_squared_error: nan - root_mean_squared_error: nan - false_negatives_19: 5581.0000 - true_negatives_19: 7927.0000 - false_positives_19: 30.0000 - true_positives_19: 30.0000 - binary_accuracy: 0.5865 - val_loss: nan - val_mean_squared_error: nan - val_root_mean_squared_error: nan - val_false_negatives_19: 1408.0000 - val_true_negatives_19: 1408.0000 - val_false_positives_19: 0.0000e+00 - val_true_positives_19: 0.0000e+00 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      " 17/106 [===>..........................] - ETA: 52s - loss: nan - mean_squared_error: nan - root_mean_squared_error: nan - false_negatives_19: 337.0000 - true_negatives_19: 1839.0000 - false_positives_19: 0.0000e+00 - true_positives_19: 0.0000e+00 - binary_accuracy: 0.8451"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[182], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m train_len_fe \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(os\u001b[39m.\u001b[39mwalk(org_path \u001b[39m/\u001b[39m class_paths[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTrain\u001b[39m\u001b[39m\"\u001b[39m))[\u001b[39m0\u001b[39m][\u001b[39m2\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m history1 \u001b[39m=\u001b[39m metamorph\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      4\u001b[0m     tr\u001b[39m.\u001b[39;49mrepeat(),\n\u001b[0;32m      5\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_len_fe[\u001b[39mint\u001b[39;49m(\u001b[39mlen\u001b[39;49m(train_len_fe) \u001b[39m*\u001b[39;49m trsplit[\u001b[39m0\u001b[39;49m]):\u001b[39mint\u001b[39;49m(\u001b[39mlen\u001b[39;49m(train_len_fe) \u001b[39m*\u001b[39;49m trsplit[\u001b[39m1\u001b[39;49m])]) \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m batch_size,\n\u001b[0;32m      7\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_len_fe[\u001b[39mint\u001b[39;49m(\u001b[39mlen\u001b[39;49m(train_len_fe) \u001b[39m*\u001b[39;49m valsplit[\u001b[39m0\u001b[39;49m]):\u001b[39mint\u001b[39;49m(\u001b[39mlen\u001b[39;49m(train_len_fe) \u001b[39m*\u001b[39;49m valsplit[\u001b[39m1\u001b[39;49m])]) \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m batch_size,\n\u001b[0;32m      8\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval\u001b[39m.\u001b[39;49mrepeat()\n\u001b[0;32m      9\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[0;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    629\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\SWQA\\miniconda3\\envs\\tf-directml38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_len_fe = list(os.walk(org_path / class_paths[0] / \"Train\"))[0][2]\n",
    "\n",
    "history1 = metamorph.fit(\n",
    "    tr.repeat(),\n",
    "    epochs=100,\n",
    "    steps_per_epoch=len(train_len_fe[int(len(train_len_fe) * trsplit[0]):int(len(train_len_fe) * trsplit[1])]) // batch_size,\n",
    "    validation_steps=len(train_len_fe[int(len(train_len_fe) * valsplit[0]):int(len(train_len_fe) * valsplit[1])]) // batch_size,\n",
    "    validation_data=val.repeat()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtstnew = te.filter(lambda x, y: tf.reduce_all(y[0] == tf.constant([1., 0.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dtstnew.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]], shape=(64, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i in dtstnew.take(1):\n",
    "    print(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.7645258>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.losses.softmax_cross_entropy(tf.constant([1., 0.]), tf.constant([0.512, 0.65]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metamorph.predict(\n",
    "    dtstnew.take(1)    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in metamorph.layers[:25]:\n",
    "   layer.trainable = False\n",
    "for layer in metamorph.layers[25:]:\n",
    "   layer.trainable = True\n",
    "   \n",
    "from tensorflow.keras.optimizers import SGD\n",
    "metamorph.compile(\n",
    "   optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "   loss='binary_crossentropy',\n",
    "   metrics=[\n",
    "        tf.keras.metrics.MeanSquaredError(),\n",
    "        tf.keras.metrics.RootMeanSquaredError(),\n",
    "        tf.keras.metrics.F1Score(),\n",
    "        \"accuracy\"\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = metamorph.fit(\n",
    "    tr.repeat(),\n",
    "    epochs=25,\n",
    "    batch_size=batch_size,\n",
    "    steps_per_epoch=len(list(os.walk(org_path / class_paths[0] / \"Train\"))[0][2]) // batch_size,\n",
    "    validation_steps=len(list(os.walk(org_path / class_paths[0] / \"Val\"))[0][2]) // batch_size,\n",
    "    validation_data=val.repeat()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = (tf.TensorSpec(shape=(None, *input_shape), dtype=tf.uint8),\n",
    "                 tf.TensorSpec(shape=(None, 1), dtype=tf.uint8))\n",
    "\n",
    "train_dataset2 = tf.data.Dataset.from_generator(\n",
    "            lambda: __data_gen(\"Train\", class_paths[1]),\n",
    "            output_signature=signature\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt in train_dataset2:\n",
    "    print(tt[0][1].shape)\n",
    "    plt.imshow(tt[0][1], interpolation='nearest')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metamorph.evaluate(\n",
    "    te.repeat(),\n",
    "    steps=len(list(os.walk(org_path / class_paths[0] / \"Test\"))[0][2]) // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_f1(0.9561, 0.9509)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1\n",
    "\n",
    "false_negatives 0.0\n",
    "true_negatives  1142.0\n",
    "false_positives 1.0\n",
    "true_positives  5033.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W0\n",
    "\n",
    "false_negatives 0.0\n",
    "true_negatives  1140.0\n",
    "false_positives 3.0\n",
    "true_positives  5033.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = (tf.TensorSpec(shape=(None, *input_shape), dtype=tf.uint8),\n",
    "                 tf.TensorSpec(shape=(None, 1), dtype=tf.uint8))\n",
    "\n",
    "train_dataset3 = tf.data.Dataset.from_generator(\n",
    "            lambda: __data_gen(\"Train\", class_paths[2]),\n",
    "            output_signature=signature\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metamorph.evaluate(\n",
    "    train_dataset3.repeat(),\n",
    "    steps=len(list(os.walk(org_path / class_paths[2] / \"Train\"))[0][2]) // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives 9.0\n",
    "true_negatives  9058.0\n",
    "false_positives 105.0\n",
    "true_positives  204.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
